During the remainder of this paper, whenever the k-plus criterion is optimized, the original data matrix is simply extended and the original k-means criterion $SSE$ is optimized. For a multicriterion objective such as the k-plus criterion, this corresponds to a rather basic approach, and future research may investigate more sophisticated optimization schemes for k-plus anticlustering [e.g., see @brusco2012; @brusco2019]. In this paper, however, I am primarily concerned with investigating the properties of new objective itself rather than extending the state of the art on multicriterion optimization methods. 

Which of these objectives is pursued depends on a researchers' needs. In the most basic---and arguably most important---case, k-plus anticlustering can be used to not just minimize differences with regard to the mean of variables but also their variance. Measures of location and spread are arguably most important to researchers when they "eyeball" their data and they are routinely reported as characterizations of a data set. Hence, by default, the k-plus objective is refered to when considering the mean and the variance of variables in the anticlustering process. 

While less routinely reported, skewness are kurtosis are also important descriptive characterizations of a data set [@decarlo1997; @westfall2014]. To optimize overall similarity between groups, it may thus be desirable to also minimize differences with regard to these distribution moments. In principle, any other higher order moments can also be included as part of the k-plus objective. Futhermore, k-plus anticlustering can also be used to obtain similar covariance structures among groups. This approach may be of interest in cross validation applications where prediction accuracy depends on the correlations among features and criteria [@zeng2000; @papenberg2020]. Interestingly, in each case, the k-plus criterion can be reduced to an augmentation of the original data matrix, leaving the original k-means objective unchanged. 

## Bicriterion optimization model

```{r echo = FALSE}
# From Wikipedia on Multi-objective optimization:

# Without additional subjective preference information, all Pareto optimal
# solutions are considered equally good. Researchers study multi-objective
# optimization problems from different viewpoints and, thus, there exist
# different solution philosophies and goals when setting and solving them.
# The goal may be to find a representative set of Pareto optimal
# solutions, and/or quantify the trade-offs in satisfying the different
# objectives, and/or finding a single solution that satisfies the
# subjective preferences of a human decision maker (DM).

# The most preferred results can be found using different philosophies.
# Multi-objective optimization methods can be divided into four
# classes. In so-called no preference methods, no DM is expected to be
# available, but a neutral compromise solution is identified without
# preference information. The other classes are so-called a priori, a
# posteriori and interactive methods and they all involve preference
# information from the DM in different ways.

# Solving a multi-objective optimization problem is sometimes understood
# as approximating or computing all or a representative set of Pareto
# optimal solutions.

# Scalarizing a multi-objective optimization problem is an a priori
# method, which means formulating a single-objective optimization problem
# such that optimal solutions to the single-objective optimization problem
# are Pareto optimal solutions to the multi-objective optimization
# problem. In addition, it is often required that every Pareto optimal
# solution can be reached with some parameters of the scalarization.

```

- pragmatic solution [easy and practical approach, @marler2010;
@naidu2014]: formalize the weighted-sum objective and use the
weighted-sum approach. Then check out whether the simplest version is
sufficient in this case (but see the problems of weighted sum approach
in several contributions by Brusco et al.). Refer to @marler2010 to
argue for weighted sum for the current problem

- it should be noted that both mathematical objectives capture different
aspects of an underlying substantive objective, that is to maximize
similarity of data distributions between different groups

- Weighted sum approach works well on this specific problem [although in
general there are caveats to the weighted-sum method, see @brusco2019].
is fast, good results. in fact, the objectives seem to work well
together

- weighted sum approach generates a single solution from the
(approximated) pareto set

- In this paper: Formalization of the objective function, recognition
that this formulation does not change the basic structure of the k-means
objective, because it reduces to augmentation of the data input

- not interested in the Pareto efficient set! Because: Overall
similarity should be maximized, which requires that both criteria are
satisfied to a strong degree (not interested in just maximizing
similarity wrt variance; this may be interesting in other applications).
Instead: A tradeoff is possible, and in many cases, simultaneous
optimization will meet both criteria almost as well as optimizing just
either criterion. To justify this approach: show the pareto front, which
is not a diagonal / circle [see @brusco2012] but a RIGHT TRIANGLE! (this
is probably because this is *anti*clustering!)

- Evaluation will consist of a comparison of different objectives based
on the same (simple) exchange algorithm

### Weight selection

- How to select weights? (Oftentimes: for equal weights, the results
are good)

- Preference to weight [e.g., @marler2010]. However, the relationship
between weights and outcome is not always straightforward and the
results may disappoint. On the one hand, vastly different weights need
not lead to different solutions; and even equal weights can be
sufficient if the solution space offers partitions that maximize both
objectives at the same time. "the solution may not preserve oneâ€™s
initial preferences no matter how the weights are set"; "even if one
determines acceptable values for the weights a priori, the final
solution may not accurately reflect initial preferences" [@marler2010,
p. 860].

- Standardization of the extended data matrix to ensure that the two
criterion functions "do not differ markedly in scale" [@brusco2019].
See Figure 1: the objectives do differ in scale, because k-variance
is based on a quadratic distance and therefore has larger values.

- Using variable weighting (see Steinley, 2006, p. 13), we can
adjust the relative importance of minimizing differences in means
and variances. Standard in `anticlust`: Equal weight, this is
achieved by first creating the new variables, representing
the squared differences from the mean, and then standardizing
the entire feature matrix. If $N$ is large enough (relative to $K$),
there is usually no need for weighting.
