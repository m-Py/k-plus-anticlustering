
## Bicriterion optimization model

```{r echo = FALSE}
# From Wikipedia on Multi-objective optimization:

# Without additional subjective preference information, all Pareto optimal
# solutions are considered equally good. Researchers study multi-objective
# optimization problems from different viewpoints and, thus, there exist
# different solution philosophies and goals when setting and solving them.
# The goal may be to find a representative set of Pareto optimal
# solutions, and/or quantify the trade-offs in satisfying the different
# objectives, and/or finding a single solution that satisfies the
# subjective preferences of a human decision maker (DM).

# The most preferred results can be found using different philosophies.
# Multi-objective optimization methods can be divided into four
# classes. In so-called no preference methods, no DM is expected to be
# available, but a neutral compromise solution is identified without
# preference information. The other classes are so-called a priori, a
# posteriori and interactive methods and they all involve preference
# information from the DM in different ways.

# Solving a multi-objective optimization problem is sometimes understood
# as approximating or computing all or a representative set of Pareto
# optimal solutions.

# Scalarizing a multi-objective optimization problem is an a priori
# method, which means formulating a single-objective optimization problem
# such that optimal solutions to the single-objective optimization problem
# are Pareto optimal solutions to the multi-objective optimization
# problem. In addition, it is often required that every Pareto optimal
# solution can be reached with some parameters of the scalarization.

```

- pragmatic solution [easy and practical approach, @marler2010;
@naidu2014]: formalize the weighted-sum objective and use the
weighted-sum approach. Then check out whether the simplest version is
sufficient in this case (but see the problems of weighted sum approach
in several contributions by Brusco et al.). Refer to @marler2010 to
argue for weighted sum for the current problem

- it should be noted that both mathematical objectives capture different
aspects of an underlying substantive objective, that is to maximize
similarity of data distributions between different groups

- Weighted sum approach works well on this specific problem [although in
general there are caveats to the weighted-sum method, see @brusco2019].
is fast, good results. in fact, the objectives seem to work well
together

- weighted sum approach generates a single solution from the
(approximated) pareto set

- In this paper: Formalization of the objective function, recognition
that this formulation does not change the basic structure of the k-means
objective, because it reduces to augmentation of the data input

- not interested in the Pareto efficient set! Because: Overall
similarity should be maximized, which requires that both criteria are
satisfied to a strong degree (not interested in just maximizing
similarity wrt variance; this may be interesting in other applications).
Instead: A tradeoff is possible, and in many cases, simultaneous
optimization will meet both criteria almost as well as optimizing just
either criterion. To justify this approach: show the pareto front, which
is not a diagonal / circle [see @brusco2012] but a RIGHT TRIANGLE! (this
is probably because this is *anti*clustering!)

- Evaluation will consist of a comparison of different objectives based
on the same (simple) exchange algorithm

### Weight selection

- How to select weights? (Oftentimes: for equal weights, the results
are good)

- Preference to weight [e.g., @marler2010]. However, the relationship
between weights and outcome is not always straightforward and the
results may disappoint. On the one hand, vastly different weights need
not lead to different solutions; and even equal weights can be
sufficient if the solution space offers partitions that maximize both
objectives at the same time. "the solution may not preserve oneâ€™s
initial preferences no matter how the weights are set"; "even if one
determines acceptable values for the weights a priori, the final
solution may not accurately reflect initial preferences" [@marler2010,
p. 860].

- Standardization of the extended data matrix to ensure that the two
criterion functions "do not differ markedly in scale" [@brusco2019].
See Figure 1: the objectives do differ in scale, because k-variance
is based on a quadratic distance and therefore has larger values.

- Using variable weighting (see Steinley, 2006, p. 13), we can
adjust the relative importance of minimizing differences in means
and variances. Standard in `anticlust`: Equal weight, this is
achieved by first creating the new variables, representing
the squared differences from the mean, and then standardizing
the entire feature matrix. If $N$ is large enough (relative to $K$),
there is usually no need for weighting.
