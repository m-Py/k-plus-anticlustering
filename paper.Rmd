---
title             : "An optimal anticlustering method to maximize stimulus dispersion in experiments"
shorttitle        : "Maximum stimulus dispersion"

author:
  - name          : "Martin Papenberg"
    affiliation   : "1"
    corresponding : yes
    address       : "Heinrich-Heine-Universität Düsseldorf, Institut für Experimentelle Psychologie, Universitätsstraße 1, 40225 Düsseldorf, Germany"
    email         : "martin.papenberg@hhu.de"
  - name          : "Martin Breuer"
    affiliation   : "1"
    corresponding : no
  - name          : "Max Diekhoff"
    affiliation   : "1"
    corresponding : no
  - name          : "Gunnar W. Klau"
    affiliation   : "1"
    corresponding : no

affiliation:
  - id            : "1"
    institution   : "Heinrich Heine University Düsseldorf"
    

authornote: |

  Martin Papenberg, Department of Experimental Psychology, Heinrich 
  Heine University Düsseldorf. Martin Breuer, Gunnar W. Klau, Max Diekhoff, 
  Department of Computer Science, Heinrich Heine University Düsseldorf.
  
abstract: |

    When assigning stimuli to experimental conditions, researchers strive for high similarity between stimulus sets and high pairwise dissimilarity of stimuli within sets. Because stimulus assignment is usually inadequate when done manually, automated algorithmic approaches are preferred. Brusco et al. (2020) proposed a bicriterion algorithm (BILS) to obtain stimulus partitionings that simultaneously satisfy two anticlustering criteria: the diversity, corresponding to between-set similarity, and the dispersion, corresponding to pairwise within-set dissimilarity. As a heuristic, however, the BILS does not necessarily identify globally optimal criterion values. We present a novel exact algorithm that returns (multiple) globally optimal partitions with regard to the dispersion. Despite its theoretical computational hardness, our method scales to rather large data sets and can be applied to solve most real-world use cases. In a simulation study, we evaluate several options to combine our optimal approach with the BILS heuristic, which -- due to its bicriterion approach -- naturally lends itself to providing high diversity on top of an optimal dispersion. We also provide two further extensions to the BILS: First, the dispersion and the diversity can be optimized on the basis of different dissimilarity matrices. Second, we allow that other anticlustering objectives of between-group similarity -- such as the k-means or k-plus objectives -- can be optimized instead of only the diversity. The original BILS as well as our extensions are freely available via the free and open source R package `anticlust`. Practical examples are included to illustrate their application.
  
bibliography      : ["lit.bib"]
  
keywords          : "Anticlustering, maximum dispersion, optimal algorithm, bicriterion optimization"
wordcount         : "12345"

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

output            : 
  papaja::apa6_pdf

header-includes:
  - \usepackage{setspace}
  - \usepackage{float}
  - \usepackage{amsmath}
  - \usepackage{hyperref}
  - \floatstyle{plaintop}
  - \restylefloat{figure}
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother
  - |
    \makeatletter
    \renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
      \hskip -\arraycolsep
      \let\@ifnextchar\new@ifnextchar
      \array{#1}}
    \makeatother

csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa7"

---

```{r setup, include = FALSE}
library(papaja) # use the development version: `remotes::install_github("crsh/papaja@devel")`; currently 0.1.1.9001
library(anticlust)
library(knitr)
# library(dplyr)
# library(ggplot2)
# library(tidyr)
# library(DescTools)
# for formatting numbers in Rmarkdown, use my package prmisc (https://github.com/m-Py/prmisc)
library(prmisc) # remotes::install_github("m-Py/prmisc") 
options(digits = 2)
knitr::opts_chunk$set(message=FALSE, warning = FALSE, echo = FALSE, dev = "cairo_pdf") 

```


## Outline

- Start with use case: Stimulus assignment in within-subjects experiments (and stick with it throughout the paper, only briefly mention other use cases)
  * Needed: high similarity between stimulus set to reduce variance in responses attributed to other factors than the experimental manipulation. This is possible using `anticlust`, which has been applied many times since its introduction in @papenberg2020 (cite references)
  * Also needed (point of this paper!): High pairwise dissimilarity of stimuli in the same set. 
- Simultaneous optimization of between-set similarity and pairwise within-set dissimilarity was introduced by Brusco et al.'s alogrithm, which is also available in `anticlust` since 2021 (version 0.6.0)
- Here, we provide researchers with a practical introduction to their method and also present several extensions, which allow it to cover more use cases
  (1) Always return optimal solution
  (2) Use different distance matrix for dispersion and diversity (if different information is needed for both criteria, or to induce custom cannot-link constraints)
  (3) Extend the BILS's capacities towards other measures of between-group similarity (k-means / k-plus)
- Technical introduction to "vanilla" BILS
- Technical introduction to our extensions
  * Optimal dispersion method: Basic algorithm + graph coloring ILP
    * How to maintain optimal dispersion while the BILS runs? Outline three approaches!
  * Different distance matrices: does not change algorithm, just computation / implementation
  * Extend towards k-means: Use squared Euclidean distance (not really extension, just different input); compute "average" diversity if group sizes are unequal (k-plus is basically the same, but do not use the additional k-plus variables for the dispersion distance matrix)
- Simulation Study
  (1) How often does vanilla BILS find optimal solutions
  (2) Which of the three extension is best for optimizing between-group similarity while maintaining optimal dispersion?
- Application (presenting R code)
  * Optimize k-plus criterion using norming data; dispersion is based on pairwise orthographic dissimilarity between words
- Discussion

## Introduction

In within-subjects experiments, participants are presented with several stimulus sets that are affiliated with the different experimental conditions. Due to carry-over effects, showing the same stimuli in different conditions is oftentimes prohibited. This is evident in studies on memory, where studying a list of words in one conditions necessarily makes it impossible to repeat their study without being influenced by the earlier study phase; memory cannot be erased after an experimental block has been completed [@lahl2006]. While the experimental logic dictates that different lists must be used, the lists should be as parallel as possible with regard to variables that affect the response variable. @lintz2021 gave two reasons as to why it is important that study participants should be confronted with balanced lists: (a) if lists are not sufficiently parallel, the variance of within-subjects effect sizes due to the experimental manipulation will be inflated, reducing statistical power---if there is no proper statistical control of the stimulus materials, which is often the case [@judd2012]; (b) highly unbalanced sets may introduce secondary effects beyond the influence of the intrinsic stimulus features. For example, highly biased lists may induce a strategic behavior shift between experimental blocks, possibly due to suspicion, boredom or frustration. These effects invalidate any observed differences between conditions and importantly, this bias cannot be accounted for via statistical techniques.

Traditionally, assigning stimuli to experimental conditions was done manually [e.g., @schaper2019metamory] or randomly [e.g., @kroneisen2018], both of which methods however do not ensure that the stimulus sets will be similar [@papenberg2020; @cutler1981; @vancasteren2007; @armstrong2012]. Generally, automated approaches are preferred that quantify similarity on the basis of the stimulus features and use an algorithm to assign stimuli in such a way that this similarity is optimized [@brusco2019; @papenberg2020]. One approach that has recently gained traction

**Using anticlustering to equate stimulus sets**

**BUT DISPERSION IS ALSO IMPORTANT!**

For example, in tasks of recognition memory, participants commonly have to decide if a target stimuli (e.g., a word) has been presented in an earlier phase of the experiment. In this case, words that are orthographically similar to a target word should serve as distractors. 

The BILS algorithm has been available in the anticlust package since 2021, but we assume that many researchers do not yet know about its potential, also given that the introduction by @brusco2019 was rather technical in nature. For now, users seem to rely on the unicriterion methods focusing on between-set similarity only. Therefore, we provide readers with an application-focused introduction and extend BILS with parameters that may be useful when designing experiments. 

--- 

**OLD**

Anticlustering refers to the process of partitioning elements into disjoint groups with the goal of obtaining high between-group similarity and high within-group heterogeneity [@brusco2019; @spath1986; @valev1998; @valev1983]. Anticlustering thereby reverses the logic of its better known twin---cluster analysis---which seeks homogeneity within clusters and separation between clusters [@rokach2005]. Anticlustering has many applications in research psychology [@steinley2006; @brusco2019; @papenberg2020]. Examples include splitting tests into parts of equal difficulty [@gierl2017], assigning students to work groups [@baker2002], and assigning stimuli to different, but parallel experimental conditions [@lahl2006]. Solving anticlustering problems "by hand" is a tedious and time-consuming task, and the quality of manual partitioning is usually subpar. Fortunately, anticlustering problems can be formalized as mathematical optimization problems [e.g., @baker2002; @brusco2019; @spath1986; @fernandez2013] and accessible open source software solutions to tackling these problems exist [@papenberg2020]. 

Anticlustering methods are characterized by (a) an objective function that quantifies between-group similarity and/or within-group heterogeneity, and (b) an algorithm that determines how elements are assigned to groups to maximize the objective function. Several anticlustering objective functions use pairwise dissimilarity ratings such as the Euclidean distance as input. The most prominent criterion of this kind is the *diversity*, which is the total sum of pairwise dissimilarities between elements within the same group [@brusco2019; @gallego2013]. By considering pairwise dissimilarities between elements in the same group, the diversity criterion reflects the total degree of within-group heterogeneity. High within-group diversity simultaneously ensures high between-group similarity.[^equalsizedgroups] Another important anticlustering criterion based on the information in a dissimilarity matrix is the *dispersion*, which is the minimum dissimilarity between any two elements within the same group [@fernandez2013]. Maximizing the dispersion increases within-group heterogeneity by ensuring that any two elements in the same group are as dissimilar from each other as possible. @brusco2019 convincingly argued that anticlustering applications striving for within-group heterogeneity should incorporate both dispersion and diversity, and they presented a bicriterion algorithm to approximate the Pareto efficient set of solutions according to both criteria. 

[^equalsizedgroups]: As will be shown later, the diversity objective only strictly equalizes within-group heterogeneity and between-group similarity when groups are equal-sized.

Oftentimes, partitioning applications in psychology are focused on between-group similarity rather than within-group heterogeneity, even though both goals usually coincide. High between-group similarity is for example desirable when designing experimental conditions using different stimulus sets that should be as similar as possible with regard to response-relevant attributes [@lahl2006]. Such stimulus selection tasks are usually conducted on the basis of attribute data and not on pairwise (dis)similarity ratings. That is, individual stimuli are numerically coded on relevant dimensions [@dry2009]. For stimuli in psycholinguistic experiments, attributes may consist of ratings for imagery and concreteness, as well as orthographic variables [@friendly1982]. In other cases, attributes are binary and may represent the presence or absence of a feature [@tversky1977]. When attribute values are available, anticlustering approaches that do not require a dissimilarity matrix[^dissimilarityfromfeatures] can be used to partition the data. K-means is probably the best-known clustering objective that can directly be computed on attribute values. In k-means clustering, the sum of the squared Euclidean distances between data points and their cluster centers is minimized, usually using the k-means heuristic [@jain2010; @steinley2006; @brusco2006branch]. Minimizing the k-means criterion simultaneously maximizes between-cluster separation and within-cluster homogeneity [@aloise2009np]. Reversing the k-means objective function---using maximization instead of minimization---has been recognized as a useful approach when aiming for high between-group similarity [@spath1986; @valev1998; @valev1983]. Specifically, as @spath1986 noted, k-means anticlustering minimizes differences with regard to the means of the numeric attributes across clusters. However, other distribution characteristics---such as the variance---are not targeted. @papenberg2020 showed that k-means anticlustering tends to over-optimize between-group similarity with regard to the mean at the cost of similarity in variance. However, when aiming for overall between-group similarity, neglecting all distribution characteristics other than the mean is misguided; similar means can be obtained even when the underlying distributions are clearly different [e.g., @anscombe1973]. 

[^dissimilarityfromfeatures]: It is still possible to convert the attribute data into a dissimilarity matrix, e.g. by computing all pairwise Euclidean distances, and then optimize a distance-based anticlustering criterion to obtain a partitioning. For Likert scale data or binary attributes, the Manhattan distance may be preferred over the Euclidean distance; for mixed-type attributes, it is even possible to compute a combined distance metric [@rokach2005].

To optimize overall between-group similarity---and hence to overcome the limitations of k-means anticlustering---this paper introduces k-plus anticlustering. K-plus is an extension of the k-means objective that quantifies between-group similarity as discrepancy with regard to several distribution characteristics instead of only the mean. Specifically, k-plus offers the possibility to minimize differences with regard to the variance and higher order moments such as skewness and kurtosis. After formally introducing the k-plus objective, two simulation studies show that k-plus anticlustering is well-suited to create groups having minimal differences according to multiple distribution characteristics, significantly outperforming traditional criteria such as the diversity and the k-means objective. Practical examples illustrate how readers can easily apply k-plus anticlustering using the free and open source software package `anticlust` [@papenberg2020; @R-anticlust], an extension to the popular statistical programming language R [@R-base].

# Evaluation

Two simulation studies were conducted to evaluate the new k-plus objective for anticlustering. Simulation 1 compared a selected number of weighting schemes for the k-plus criterion $\mathit{SSE_{kplusGeneralized}}$. The results of this initial test determined the benchmark implementation of k-plus anticlustering that was used as contestant in the follow-up simulation. Simulation 2 was a large scale comparison of the k-plus objective and the most important traditional anticlustering objectives striving for between-group similarity: the diversity and the k-means objective. 

The simulation studies were implemented using the statistical programming language R [Version 4.2, @R-base]. The R package `anticlust` [Version 0.6.1, @R-anticlust; @papenberg2020] was used to optimize the anticlustering objectives. The R package `faux` [Version 1.1.0, @R-faux] was used to generate the multivariate normal data sets that were processed during Simulation 2. The R packages `dplyr` [Version 1.0.7, @R-dplyr], `ggplot2` [Version 3.3.5, @R-ggplot2], `papaja` [Version 0.1.1.9001, @R-papaja], `tidyr` [Version 1.1.3, @R-tidyr], `fossil` [Version 0.4.0, @R-fossil], and `DescTools` [Version 0.99.45, @R-desctools] were used for data analysis and result presentation. The simulation study is fully reproducible via code and data that has been made accessible in an accompanying OSF repository [@osf2023].

## Optimization algorithm

In both simulation studies, the same local maximum search was applied to optimize the competing anticlustering objectives [Method LCW, @weitz1998]. Building on an initial random allocation, the algorithm proceeds by swapping elements between groups in such a way that each swap improves the objective criterion by the largest possible margin. That is, it starts with the first element and simulates all exchanges with elements that are currently assigned to a different group. After each exchange has been evaluated, the one exchange is realized that improves the objective function the most. No exchange is realized if no improvement is possible. The exchange process is repeated for each element. After that, the procedure restarts at the beginning and is repeated until an iteration through the entire data set no longer yields an improvement. To obtain better results, this local maximum search may be initialized multiple times [@spath1986]. In the simulation studies, five repetitions were used. Note that the local maximum search can be performed on the basis of any arbitrary initial grouping. In particular, the initial grouping determines the sizes of the anticlusters, because the exchange procedure following the set-up never changes the sizes of the groups. While the data sets in the simulation studies were always partitioned into equal-sized groups, it would also be possible to ensure that the group sizes differ by 1 at most if an even split is not possible; even different-sized groups can be requested if required by the application.

## Conditions

For Simulation 2, I generated 10,000 data sets following a normal distribution. The data sets were subsequently processed by the competing methods. The following properties were determined randomly for each data set: (a) the sample size $N$ varied between 24 and 300 with intermediate steps of 12 so that each data set could be split evenly into $K = 2$, $3$, and $4$ groups; (b) the number of features varied between 2 and 5; (c) the standard deviation of all features was set to 1, 2 or 3 (the mean was always zero); (d) the correlation between all features was $r = 0$, $r = .1$, $r = .2$, $r = .3$, $r = .4$ or $r = .5$. All anticlustering methods were applied to each of the 10,000 data sets using $K = 2$, $K = 3$ and $K = 4$ (i.e., each method was applied 30,000 times). Groups sizes were always equal. 

## Evaluation criteria


## Results

## Example Application II: Small data set ($N = 96$)

The simulation study indicated that k-plus may show decreased performance for smaller group sizes. Therefore, a second application illustrates that k-plus anticlustering yields satisfactory results in practice even when group sizes are smaller. I make use of a norming data set of 96 word stimuli that was contributed to the `anticlust` package by Marie L. Schaper [@schaper2019metacognitive; @schaper2019metamory]. After loading the `anticlust` package, the data set can be accessed as follows: 

```{r, echo = TRUE}
data(schaper2019)
```

# Discussion

\newpage

# References

\begingroup
<div id="refs" custom-style="Bibliography"></div>
\endgroup

